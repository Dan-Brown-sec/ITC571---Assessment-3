# malrob/model.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional

import torch
import torch.nn as nn
from sklearn.ensemble import RandomForestClassifier


def make_rf_binary(
    random_state: int = 42,
    n_estimators: int = 500,
    max_depth: Optional[int] = None,
    n_jobs: int = -1,
    class_weight: Optional[str] = "balanced_subsample",
) -> RandomForestClassifier:
    return RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=random_state,
        n_jobs=n_jobs,
        class_weight=class_weight,
    )


@dataclass
class BinaryNNConfig:
    input_dim: int
    hidden_dim: int = 512
    n_res_blocks: int = 5
    dropout: float = 0.2
    mid_dim1: int = 128
    mid_dim2: int = 64


class ResidualBlock(nn.Module):
    def __init__(self, dim: int, dropout: float):
        super().__init__()
        self.block = nn.Sequential(
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
        )
        self.act = nn.GELU()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.act(self.block(x) + x)


class BinaryResidualMLP(nn.Module):
    def __init__(self, cfg: BinaryNNConfig):
        super().__init__()

        self.input_layer = nn.Sequential(
            nn.Linear(cfg.input_dim, cfg.hidden_dim),
            nn.BatchNorm1d(cfg.hidden_dim),
            nn.GELU(),
        )

        self.res_blocks = nn.ModuleList(
            [ResidualBlock(cfg.hidden_dim, cfg.dropout) for _ in range(cfg.n_res_blocks)]
        )

        self.mid = nn.Sequential(
            nn.Linear(cfg.hidden_dim, cfg.mid_dim1),
            nn.BatchNorm1d(cfg.mid_dim1),
            nn.GELU(),
            nn.Dropout(cfg.dropout),
            nn.Linear(cfg.mid_dim1, cfg.mid_dim2),
            nn.BatchNorm1d(cfg.mid_dim2),
            nn.GELU(),
        )

        self.output_layer = nn.Linear(cfg.mid_dim2, 1)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.input_layer(x)
        for block in self.res_blocks:
            x = block(x)
        x = self.mid(x)
        return self.output_layer(x)
