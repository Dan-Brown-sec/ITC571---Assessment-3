from __future__ import annotations

import json
from pathlib import Path
from collections.abc import Mapping, Sequence
from typing import Any, Dict, List, Optional, Literal

import pandas as pd


FeatureMode = Literal["summary", "full"]


def _is_seq(x: Any) -> bool:
    return isinstance(x, Sequence) and not isinstance(x, (str, bytes, bytearray))


def flatten_numeric(prefix: str, obj: Any, out: Dict[str, Any]) -> None:
    """
    Recursively flatten numeric/boolean values from nested dicts/lists into a flat dict.

    Notes
    -----
    - Strings/bytes are ignored.
    - Only numeric/bool leaves become features.
    """
    if isinstance(obj, Mapping):
        for k, v in obj.items():
            key = f"{prefix}_{k}" if prefix else str(k)
            if isinstance(v, (int, float, bool)):
                out[key] = int(v) if isinstance(v, bool) else float(v)
            elif isinstance(v, Mapping) or _is_seq(v):
                flatten_numeric(key, v, out)

    elif _is_seq(obj):
        for idx, v in enumerate(obj):
            key = f"{prefix}_{idx}" if prefix else str(idx)
            if isinstance(v, (int, float, bool)):
                out[key] = int(v) if isinstance(v, bool) else float(v)
            elif isinstance(v, Mapping) or _is_seq(v):
                flatten_numeric(key, v, out)


def build_feature_row(
    sample: Dict[str, Any],
    *,
    include_family: bool = False,
    family_key: str = "avclass",
    feature_mode: FeatureMode = "full",
) -> Dict[str, Any]:
    """
    Turn a single EMBER JSON sample into a flat feature row.

    feature_mode
    ------------
    - "summary": store histogram/byteentropy as mean/min/max only
    - "full": store all histogram bins and full byteentropy grid cells

    Returns
    -------
    dict with:
      - label (0/1)
      - optional family (string)
      - flattened numeric features
    """
    row: Dict[str, Any] = {}

    # Binary label: 0 benign, 1 malware
    row["label"] = sample.get("label", -1)

    # Optional family label
    if include_family:
        fam = sample.get(family_key, None)
        if fam in (None, "", "UNKNOWN", "SINGLETON"):
            fam = "unknown"
        row["family"] = fam



    # Core numeric sections
    flatten_numeric("general", sample.get("general", {}), row)
    flatten_numeric("header", sample.get("header", {}), row)
    flatten_numeric("section", sample.get("section", {}), row)
    flatten_numeric("strings", sample.get("strings", {}), row)
    flatten_numeric("datadir", sample.get("datadirectories", {}), row)

    # histogram
    hist = sample.get("histogram")
    if _is_seq(hist) and len(hist) > 0:
        if feature_mode == "full":
            for i, v in enumerate(hist):
                if isinstance(v, (int, float)):
                    row[f"hist_{i}"] = float(v)
        else:  # summary
            h = [float(x) for x in hist if isinstance(x, (int, float))]
            if h:
                row["hist_mean"] = sum(h) / len(h)
                row["hist_min"] = min(h)
                row["hist_max"] = max(h)

    # byteentropy (list of lists)
    be = sample.get("byteentropy")
    if _is_seq(be) and len(be) > 0:
        if feature_mode == "full":
            for i, sub in enumerate(be):
                if not _is_seq(sub):
                    continue
                for j, v in enumerate(sub):
                    if isinstance(v, (int, float)):
                        row[f"byteentropy_{i}_{j}"] = float(v)
        else:  # summary
            flat_be: List[float] = []
            for sub in be:
                if _is_seq(sub):
                    flat_be.extend([float(x) for x in sub if isinstance(x, (int, float))])
            if flat_be:
                row["byteentropy_mean"] = sum(flat_be) / len(flat_be)
                row["byteentropy_min"] = min(flat_be)
                row["byteentropy_max"] = max(flat_be)

    return row


def _auto_title_from_target(target_per_class: int) -> str:
    # e.g. 6000 -> 12k, 18000 -> 36k
    return f"{(target_per_class * 2) // 1000}k"


def make_ember_flat(
    ember_dir: str | Path,
    *,
    input_filename: str = "test_features.jsonl",
    target_per_class: int = 6000,
    title: Optional[str] = None,
    save_dir: str | Path | None = None,
    include_family: bool = False,
    family_key: str = "avclass",
    feature_mode: FeatureMode = "full",
    prefix: str = "ember_full",
    seed: int = 42,
) -> Path:
    """
    Create a balanced EMBER dataset of size 2*target_per_class and save as CSV.

    Output filename pattern
    -----------------------
    {prefix}_{title}_flat.csv
      - prefix default: "ember_full"
      - title default: computed from target_per_class (e.g., "12k")
      - if include_family=True, the CSV includes a string "family" column

    Notes
    -----
    - Streaming read (does not load whole JSONL into memory).
    - Stops as soon as it collects enough benign + malware samples.
    """
    ember_dir = Path(ember_dir)
    input_path = ember_dir / input_filename

    benign_rows: List[Dict[str, Any]] = []
    malware_rows: List[Dict[str, Any]] = []

    print(f"[INFO] Reading from: {input_path}")
    with input_path.open("r", encoding="utf-8") as f:
        for line in f:
            sample = json.loads(line)
            label = sample.get("label", -1)

            if label not in (0, 1):
                continue  # ignore unlabeled / unknown

            if label == 0 and len(benign_rows) < target_per_class:
                benign_rows.append(sample)
            elif label == 1 and len(malware_rows) < target_per_class:
                malware_rows.append(sample)

            if len(benign_rows) >= target_per_class and len(malware_rows) >= target_per_class:
                break

    print(f"[INFO] Collected raw samples: benign={len(benign_rows)}, malware={len(malware_rows)}")

    import random
    random.seed(seed)
    random.shuffle(benign_rows)
    random.shuffle(malware_rows)

    rows = [
        build_feature_row(
            s,
            include_family=include_family,
            family_key=family_key,
            feature_mode=feature_mode,
        )
        for s in (benign_rows + malware_rows)
    ]

    df = pd.DataFrame(rows)
    print(f"[INFO] DataFrame shape: {df.shape}")
    if "label" in df.columns:
        print("[INFO] Label counts:")
        print(df["label"].value_counts())

    if include_family and "family" in df.columns:
        print("[INFO] Top family counts:")
        print(df["family"].value_counts().head(10))

    if title is None:
        title = _auto_title_from_target(target_per_class)

    if save_dir is None:
        save_dir = ember_dir
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)

    filename = f"{prefix}_{title}_flat.csv"
    output_path = save_dir / filename

    df.to_csv(output_path, index=False)
    print(f"[INFO] Saved dataset to: {output_path}")

    return output_path


def make_ember_families_flat(
    ember_dir: str | Path,
    *,
    input_filename: str = "test_features.jsonl",
    target_per_class: int = 6000,
    title: Optional[str] = None,
    save_dir: str | Path | None = None,
    family_key: str = "avclass",
    feature_mode: FeatureMode = "full",
    prefix: str = "ember_full",
    seed: int = 42, 
) -> Path:
    """
    Convenience wrapper that produces the family-augmented dataset.

    Default title becomes e.g.:
      - 12k_families  (for target_per_class=6000)
    """
    if title is None:
        title = f"{_auto_title_from_target(target_per_class)}_families"

    return make_ember_flat(
        ember_dir,
        input_filename=input_filename,
        target_per_class=target_per_class,
        title=title,
        save_dir=save_dir,
        include_family=True,
        family_key=family_key,
        feature_mode=feature_mode,
        prefix=prefix,
        seed=seed,
    )
