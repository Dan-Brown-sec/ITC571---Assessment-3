# malrob/family_transfer_fgsm.py
from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.ensemble import RandomForestClassifier
import joblib

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader


# =========================
# Config
# =========================
@dataclass
class FamilyTransferConfig:
    repo_root: Path
    dataset_tag: str                  # "12k", "36k", ...
    top_n_families: int = 5
    test_size: float = 0.30
    eps_list: Tuple[float, ...] = (0.01, 0.05, 0.10)
    random_state: int = 42
    epochs: int = 60
    device: str = "cpu"               # "cpu" or "cuda"


# =========================
# Device handling (NEW)
# =========================
def resolve_device(requested: str) -> str:
    """
    Resolve execution device safely.
    Falls back to CPU if CUDA is requested but unavailable.
    """
    req = (requested or "cpu").lower()
    if req.startswith("cuda"):
        if torch.cuda.is_available():
            return "cuda"
        else:
            print("[WARN] CUDA requested but not available in this PyTorch build. Falling back to CPU.")
            return "cpu"
    return "cpu"


# =========================
# Models
# =========================
class FamilyMLP(nn.Module):
    def __init__(self, input_dim: int, n_classes: int):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.BatchNorm1d(512),
            nn.GELU(),
            nn.Dropout(0.2),

            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.GELU(),
            nn.Dropout(0.2),

            nn.Linear(256, n_classes),
        )

    def forward(self, x):
        return self.net(x)


# =========================
# Data hygiene
# =========================
def sanitize_nonfinite_to_nan(X: pd.DataFrame) -> pd.DataFrame:
    """Replace +/-inf with NaN so the imputer can handle it deterministically."""
    vals = X.to_numpy(dtype=float, copy=True)
    nonfinite = ~np.isfinite(vals)
    n_bad = int(nonfinite.sum())
    if n_bad > 0:
        print(f"[WARN] Non-finite values in raw features: {n_bad}. Replacing with NaN before imputation.")
        vals[nonfinite] = np.nan
    return pd.DataFrame(vals, columns=X.columns, index=X.index)


# =========================
# Attacks
# =========================
def fgsm_attack_multiclass(model: nn.Module, x: torch.Tensor, y: torch.Tensor, eps: float) -> torch.Tensor:
    model.eval()
    x_adv = x.clone().detach().requires_grad_(True)
    logits = model(x_adv)
    loss = nn.CrossEntropyLoss()(logits, y)
    model.zero_grad()
    loss.backward()
    return (x_adv + float(eps) * x_adv.grad.sign()).detach()


# =========================
# Evaluation helpers
# =========================
def save_confusion_and_report(
    y_true,
    y_pred,
    labels: List[str],
    model_name: str,
    tag: str,
    results_dir: Path,
    plots_dir: Path,
) -> float:
    acc = accuracy_score(y_true, y_pred)

    report_txt = classification_report(y_true, y_pred, digits=4, zero_division=0)
    report_dict = classification_report(y_true, y_pred, output_dict=True, zero_division=0)

    cm = confusion_matrix(y_true, y_pred, labels=labels)
    cm_df = pd.DataFrame(cm, index=labels, columns=labels)

    base = f"{model_name}_{tag}"
    results_dir.mkdir(parents=True, exist_ok=True)
    plots_dir.mkdir(parents=True, exist_ok=True)

    (results_dir / f"{base}_report.txt").write_text(report_txt)
    with open(results_dir / f"{base}_report.json", "w", encoding="utf-8") as f:
        json.dump(report_dict, f, indent=2)

    cm_df.to_csv(results_dir / f"{base}_confusion_matrix.csv")

    fig, ax = plt.subplots(figsize=(7, 6))
    im = ax.imshow(cm)
    fig.colorbar(im, ax=ax)
    ax.set_xticks(np.arange(len(labels)))
    ax.set_yticks(np.arange(len(labels)))
    ax.set_xticklabels(labels, rotation=45, ha="right")
    ax.set_yticklabels(labels)
    ax.set_title(f"{model_name} â€“ {tag}")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, int(cm[i, j]), ha="center", va="center")

    plt.tight_layout()
    fig.savefig(plots_dir / f"{base}_confusion_matrix.png", dpi=300, bbox_inches="tight")
    plt.show() 
    plt.close(fig)

    return float(acc)


# =========================
# Main runner
# =========================
def run_family_transfer_fgsm(cfg: FamilyTransferConfig) -> pd.DataFrame:
    repo_root = Path(cfg.repo_root)
    device = resolve_device(cfg.device)
    print(f"[INFO] Using device: {device}")

    data_dir = repo_root / "datasets" / "ember2018"
    models_dir = repo_root / f"models_full_{cfg.dataset_tag}"

    artifacts_dir = models_dir / "artifacts_family"
    results_dir = models_dir / "results_family"
    plots_dir = results_dir / "plots"

    for d in [artifacts_dir, results_dir, plots_dir]:
        d.mkdir(parents=True, exist_ok=True)

    family_csv = data_dir / f"ember_full_{cfg.dataset_tag}_families_flat.csv"
    if not family_csv.exists():
        raise FileNotFoundError(f"Missing families CSV: {family_csv}")

    # -------------------------
    # Load + filter data
    # -------------------------
    df = pd.read_csv(family_csv)
    df_mal = df[df["label"] == 1].copy()
    df_mal["family"] = df_mal["family"].fillna("unknown").astype(str)

    fam_counts = df_mal[df_mal["family"] != "unknown"]["family"].value_counts()
    top_fams = fam_counts.head(cfg.top_n_families).index.tolist()

    df_top = df_mal[df_mal["family"].isin(top_fams)].copy()

    print("Top families:", top_fams)
    print("Subset shape:", df_top.shape)
    print("Counts:\n", df_top["family"].value_counts())

    # -------------------------
    # Features + labels
    # -------------------------
    print("[INFO] Starting preprocessing (imputation + scaling)...")

    X = df_top.drop(columns=["label", "family"]).copy()
    y = df_top["family"].astype(str)

    X = sanitize_nonfinite_to_nan(X)
    X = X.dropna(axis=1, how="all")
    feature_cols = X.columns.tolist()

    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=cfg.test_size,
        random_state=cfg.random_state,
        stratify=y,
    )

    imputer = SimpleImputer(strategy="mean")
    X_train_imp = imputer.fit_transform(X_train)
    X_test_imp = imputer.transform(X_test)
    print("[INFO] Imputation complete.")

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_imp)
    X_test_scaled = scaler.transform(X_test_imp)
    print("[INFO] Scaling complete.")

    # -------------------------
    # RF family model
    # -------------------------
    print("[INFO] Training RandomForest (300 trees)...")

    rf = RandomForestClassifier(
        n_estimators=300,
        max_depth=None,
        class_weight="balanced",
        random_state=cfg.random_state,
        n_jobs=-1,
    )

    rf.fit(pd.DataFrame(X_train_imp, columns=feature_cols), y_train)
    print("[INFO] RandomForest training complete.")

    rf_acc_clean = save_confusion_and_report(
        y_test,
        rf.predict(pd.DataFrame(X_test_imp, columns=feature_cols)),
        top_fams,
        "RF_FAMILY",
        "clean",
        results_dir,
        plots_dir,
    )

    # -------------------------
    # NN family model
    # -------------------------
    label_to_idx = {f: i for i, f in enumerate(top_fams)}
    idx_to_label = {i: f for f, i in label_to_idx.items()}

    y_train_idx = y_train.map(label_to_idx).values
    y_test_idx = y_test.map(label_to_idx).values

    X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32, device=device)
    y_train_t = torch.tensor(y_train_idx, dtype=torch.long, device=device)
    X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32, device=device)
    y_test_t = torch.tensor(y_test_idx, dtype=torch.long, device=device)

    train_loader = DataLoader(
        TensorDataset(X_train_t, y_train_t),
        batch_size=128,
        shuffle=True,
    )

    nn_model = FamilyMLP(X_train_t.shape[1], len(top_fams)).to(device)
    opt = optim.AdamW(nn_model.parameters(), lr=7e-4, weight_decay=5e-5)
    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=cfg.epochs)

    print(f"[INFO] Training NN for {cfg.epochs} epochs...")

    for epoch in range(cfg.epochs):
        nn_model.train()
        for xb, yb in train_loader:
            opt.zero_grad()
            loss = nn.CrossEntropyLoss()(nn_model(xb), yb)
            loss.backward()
            opt.step()
        sched.step()

        if (epoch + 1) % 5 == 0 or epoch == 0:
            print(f"[INFO] NN epoch {epoch+1}/{cfg.epochs} complete.")

    print("[INFO] NN training complete.")
    print("[INFO] Evaluating clean NN performance...")

    # =========================
    # NN clean evaluation
    # =========================
    nn_model.eval()
    with torch.no_grad():
        pred_idx_clean = nn_model(X_test_t).argmax(1).cpu().numpy()

    pred_label_clean = np.array([idx_to_label[i] for i in pred_idx_clean])

    nn_acc_clean = save_confusion_and_report(
        y_test,
        pred_label_clean,
        top_fams,
        "NN_FAMILY",
        "clean",
        results_dir,
        plots_dir,
    )

    # -------------------------
    # FGSM + transfer
    # -------------------------
    print("[INFO] Starting FGSM attacks...")

    rows = []
    nn_model.eval()

    for eps in cfg.eps_list:
        print(f"[INFO] Running FGSM for eps={eps}...")

        X_adv_t = fgsm_attack_multiclass(nn_model, X_test_t, y_test_t, eps)
        X_adv_imp = scaler.inverse_transform(X_adv_t.cpu().numpy())

        nn_adv_idx = nn_model(X_adv_t).argmax(1).cpu().numpy()
        nn_adv_label = np.array([idx_to_label[i] for i in nn_adv_idx])

        rf_adv_label = rf.predict(pd.DataFrame(X_adv_imp, columns=feature_cols))

        nn_acc_adv = save_confusion_and_report(
            y_test, nn_adv_label, top_fams,
            "NN_FAMILY", f"fgsm_eps{eps}", results_dir, plots_dir
        )
        rf_acc_adv = save_confusion_and_report(
            y_test, rf_adv_label, top_fams,
            "RF_FAMILY", f"nn_fgsm_eps{eps}_transfer", results_dir, plots_dir
        )

        rows.append({
            "attack": "FGSM",
            "eps": float(eps),
            "nn_acc_clean": nn_acc_clean,
            "nn_acc_adv": nn_acc_adv,
            "rf_acc_clean": rf_acc_clean,
            "rf_acc_adv_transfer": rf_acc_adv,
        })

        print(f"[INFO] FGSM eps={eps} complete.")

    summary = pd.DataFrame(rows)
    summary.to_csv(results_dir / "family_adv_summary.csv", index=False)

    print("[INFO] FGSM evaluation complete.")
    print("[INFO] Summary saved to:", results_dir / "family_adv_summary.csv")

    return summary



__all__ = ["FamilyTransferConfig", "run_family_transfer_fgsm"]