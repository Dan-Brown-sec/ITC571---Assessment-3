# malrob/adversarial_binary.py
from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional

import numpy as np
import pandas as pd

import torch
import torch.nn as nn

from joblib import load
from sklearn.metrics import roc_curve
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt

# IMPORTANT: load the SAME architecture used in training/checkpointing
from malrob.model import BinaryNNConfig, BinaryResidualMLP


# =========================
# Config
# =========================
@dataclass
class AdversarialConfig:
    eps_list: List[float]
    pgd_steps: Dict[float, int]
    pgd_alpha: Dict[float, float]
    random_state: int = 42
    device: str = "cpu"  # "cpu" or "cuda"


# =========================
# Device handling (NEW)
# =========================
def resolve_device(requested: str) -> str:
    """
    Resolve execution device safely.
    Falls back to CPU if CUDA is requested but unavailable.
    """
    req = (requested or "cpu").lower()
    if req.startswith("cuda"):
        if torch.cuda.is_available():
            return "cuda"
        print("[WARN] CUDA requested but not available in this PyTorch build. Falling back to CPU.")
        return "cpu"
    return "cpu"


# =========================
# Utilities
# =========================
def probs_guard(probs: np.ndarray) -> np.ndarray:
    """Replace NaN/inf probs and clip to [0,1]."""
    p = np.asarray(probs, dtype=float)
    bad = ~np.isfinite(p)
    if bad.any():
        print(f"[WARN] Found {int(bad.sum())} non-finite probs; replacing with 0.5")
        p[bad] = 0.5
    return np.clip(p, 0.0, 1.0)


def youden_threshold(y_true: np.ndarray, probs: np.ndarray) -> float:
    """
    ROC-based threshold using Youdenâ€™s J = TPR - FPR.
    Handles the common 'inf' threshold returned by roc_curve.
    """
    y = np.asarray(y_true).astype(int)
    p = probs_guard(probs)

    fpr, tpr, thr = roc_curve(y, p)

    # roc_curve frequently includes an initial threshold=inf; drop non-finite thresholds
    finite = np.isfinite(thr)
    fpr, tpr, thr = fpr[finite], tpr[finite], thr[finite]

    j = tpr - fpr
    best_idx = int(np.argmax(j))
    return float(thr[best_idx])


def _to_finite_numpy(df: pd.DataFrame, *, fill_value: float = 0.0) -> np.ndarray:
    """
    Convert DataFrame -> float numpy and replace non-finite values with fill_value.
    This matches the numerical stability contract used in train.py (and avoids NaN/inf crashes).
    """
    X = df.to_numpy(dtype=float, copy=True)
    bad = ~np.isfinite(X)
    if bad.any():
        print(f"[WARN] Non-finite values in raw features: {int(bad.sum())}. Replacing with {fill_value}")
        X[bad] = float(fill_value)
    return X


def _finite_df_from(df: pd.DataFrame, *, fill_value: float = 0.0) -> pd.DataFrame:
    """
    Return a DataFrame with identical columns/index but with non-finite replaced.
    Used to keep RF feature alignment stable.
    """
    X = _to_finite_numpy(df, fill_value=fill_value)
    return pd.DataFrame(X, columns=df.columns, index=df.index)


def make_clip_to_train_range(X_train_raw: np.ndarray):
    train_min = np.min(X_train_raw, axis=0)
    train_max = np.max(X_train_raw, axis=0)

    def clip_to_train_range(X_raw: np.ndarray) -> np.ndarray:
        return np.clip(X_raw, train_min, train_max)

    return clip_to_train_range


# =========================
# Model / artifact loading
# =========================
def load_binary_artifacts(
    *,
    scaler_path: Path,
    nn_weights_path: Path,
    rf_model_path: Path,
    input_dim: int,
    device: str = "cpu",
) -> Tuple[object, nn.Module, object]:
    """
    Load scaler, NN weights, and RF model.

    NOTE: nn_weights_path must correspond to BinaryResidualMLP state_dict,
    i.e., trained by malrob.train using malrob.model.BinaryResidualMLP.
    """
    scaler_path = Path(scaler_path)
    nn_weights_path = Path(nn_weights_path)
    rf_model_path = Path(rf_model_path)

    scaler = load(scaler_path)

    nn_model = BinaryResidualMLP(BinaryNNConfig(input_dim=input_dim)).to(device)
    state = torch.load(nn_weights_path, map_location=device)
    nn_model.load_state_dict(state, strict=True)
    nn_model.eval()

    rf = load(rf_model_path)

    print("[INFO] Loaded scaler/NN/RF")
    print("  scaler:", scaler_path)
    print("  nn:", nn_weights_path)
    print("  rf:", rf_model_path)
    print("  device:", device)

    return scaler, nn_model, rf


# =========================
# Single-source split protocol (NEW)
# =========================
def make_split_and_artifacts(
    *,
    data_csv: Path,
    scaler,
    artifacts_dir: Path,
    random_state: int = 42,
    test_size: float = 0.2,
    nonfinite_fill: float = 0.0,
) -> Dict[str, Any]:
    """
    One canonical split, reused for thresholds + FGSM + PGD to avoid drift.
    Persists:
      - mal_idx.npy (indices of malware samples within X_test)
      - fam_mal.csv (family labels for malware-only test subset)
    Returns a split dict including:
      X_train_df, X_test_df (raw, as DataFrames)
      X_train_np, X_test_np (finite, numpy)
      X_train_scaled, X_test_scaled
      y_train, y_test (Series)
      fam_train, fam_test (Series)
      feature_cols
      mal_idx
      X_mal_scaled, y_mal_np
      clip_to_train_range callable
    """
    data_csv = Path(data_csv)
    artifacts_dir = Path(artifacts_dir)
    artifacts_dir.mkdir(parents=True, exist_ok=True)

    df = pd.read_csv(data_csv)

    if "label" not in df.columns or "family" not in df.columns:
        raise ValueError("Expected a families CSV with columns: ['label','family', ...features...]")

    family = df["family"].astype(str)
    y = df["label"].astype(int)
    X = df.drop(columns=["label", "family"])

    X_train_df, X_test_df, y_train, y_test, fam_train, fam_test = train_test_split(
        X, y, family,
        test_size=float(test_size),
        random_state=int(random_state),
        stratify=y,
    )

    feature_cols = X_train_df.columns.tolist()

    # Persist malware-only indices and family labels (computed ONCE)
    mal_idx = np.where(y_test.values == 1)[0]
    np.save(artifacts_dir / "mal_idx.npy", mal_idx)
    pd.Series(fam_test.values[mal_idx]).to_csv(
        artifacts_dir / "fam_mal.csv", index=False, header=["family"]
    )

    # Finite numpy versions (shared for scaling + clip bounds)
    X_train_np = _to_finite_numpy(X_train_df, fill_value=nonfinite_fill)
    X_test_np = _to_finite_numpy(X_test_df, fill_value=nonfinite_fill)

    X_train_scaled = scaler.transform(X_train_np)
    X_test_scaled = scaler.transform(X_test_np)

    # Malware-only scaled subset for attacks
    X_mal_scaled = X_test_scaled[mal_idx]
    y_mal_np = y_test.values[mal_idx]  # all ones (malware)

    # Clip bounds for inverse-scaled transfer
    clip_to_train_range = make_clip_to_train_range(X_train_np)

    print("[INFO] Split prepared and artifacts saved:")
    print("  mal_idx.npy:", artifacts_dir / "mal_idx.npy")
    print("  fam_mal.csv:", artifacts_dir / "fam_mal.csv")
    print("  X_train:", X_train_df.shape, "X_test:", X_test_df.shape)
    print("  malware in test:", int(len(mal_idx)))

    return {
        "X_train_df": X_train_df,
        "X_test_df": X_test_df,
        "y_train": y_train,
        "y_test": y_test,
        "fam_train": fam_train,
        "fam_test": fam_test,
        "feature_cols": feature_cols,
        "mal_idx": mal_idx,
        "X_train_np": X_train_np,
        "X_test_np": X_test_np,
        "X_train_scaled": X_train_scaled,
        "X_test_scaled": X_test_scaled,
        "X_mal_scaled": X_mal_scaled,
        "y_mal_np": y_mal_np,
        "clip_to_train_range": clip_to_train_range,
        "test_size": float(test_size),
        "random_state": int(random_state),
        "nonfinite_fill": float(nonfinite_fill),
    }


# =========================
# Thresholds (reuses split; NEW signature)
# =========================
def compute_clean_thresholds_from_split(
    *,
    split: Dict[str, Any],
    scaler,
    nn_model: nn.Module,
    rf,
    artifacts_dir: Path,
    device: str = "cpu",
) -> Tuple[float, float]:
    """
    Replicates Notebook 03 threshold protocol on the FULL test set
    using the canonical split dict.

    Persists clean_thresholds.json into artifacts_dir.
    """
    artifacts_dir = Path(artifacts_dir)
    artifacts_dir.mkdir(parents=True, exist_ok=True)

    y_test = split["y_test"]
    feature_cols = split["feature_cols"]

    # NN clean probs on full scaled test set
    X_test_scaled = split["X_test_scaled"]
    X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32, device=device)

    nn_model.eval()
    with torch.no_grad():
        nn_logits_clean = nn_model(X_test_t).squeeze(1)
        nn_probs_clean = torch.sigmoid(nn_logits_clean).detach().cpu().numpy()

    clean_thr_nn = youden_threshold(y_test.values, nn_probs_clean)

    # RF clean probs on full finite raw test set (DataFrame keeps feature alignment stable)
    X_test_df = split["X_test_df"][feature_cols]
    X_test_finite_df = _finite_df_from(X_test_df, fill_value=0.0)

    rf_probs_clean = rf.predict_proba(X_test_finite_df)[:, 1]
    clean_thr_rf = youden_threshold(y_test.values, rf_probs_clean)

    with open(artifacts_dir / "clean_thresholds.json", "w", encoding="utf-8") as f:
        json.dump(
            {"clean_thr_nn": float(clean_thr_nn), "clean_thr_rf": float(clean_thr_rf)},
            f,
            indent=2,
        )

    print("[INFO] Clean thresholds saved to:", artifacts_dir / "clean_thresholds.json")
    print("  clean_thr_nn:", float(clean_thr_nn))
    print("  clean_thr_rf:", float(clean_thr_rf))

    return float(clean_thr_nn), float(clean_thr_rf)


# Backward-compatible wrapper (keeps your Notebook 03 working if you prefer)
def compute_clean_thresholds(
    *,
    data_csv: Path,
    scaler,
    nn_model: nn.Module,
    rf,
    artifacts_dir: Path,
    random_state: int = 42,
    device: str = "cpu",
) -> Tuple[float, float, Dict[str, Any]]:
    """
    Backward-compatible entry point:
      - builds canonical split once
      - computes thresholds from split
      - returns (thr_nn, thr_rf, split)
    """
    split = make_split_and_artifacts(
        data_csv=data_csv,
        scaler=scaler,
        artifacts_dir=artifacts_dir,
        random_state=random_state,
        test_size=0.2,
        nonfinite_fill=0.0,
    )
    thr_nn, thr_rf = compute_clean_thresholds_from_split(
        split=split,
        scaler=scaler,
        nn_model=nn_model,
        rf=rf,
        artifacts_dir=artifacts_dir,
        device=device,
    )
    return thr_nn, thr_rf, split


# =========================
# Attacks (scaled space)
# =========================
def fgsm_attack(model: nn.Module, x: torch.Tensor, y: torch.Tensor, eps: float) -> torch.Tensor:
    x_adv = x.clone().detach().requires_grad_(True)
    logits = model(x_adv).squeeze(1)
    loss = nn.BCEWithLogitsLoss()(logits, y)
    model.zero_grad()
    loss.backward()
    x_adv = x_adv + float(eps) * x_adv.grad.sign()
    return x_adv.detach()


def pgd_attack(
    model: nn.Module,
    x: torch.Tensor,
    y: torch.Tensor,
    eps: float,
    alpha: float,
    steps: int,
) -> torch.Tensor:
    x0 = x.clone().detach()
    x_adv = x.clone().detach()

    eps = float(eps)
    alpha = float(alpha)
    steps = int(steps)

    for _ in range(steps):
        x_adv.requires_grad_(True)
        logits = model(x_adv).squeeze(1)
        loss = nn.BCEWithLogitsLoss()(logits, y)
        model.zero_grad()
        loss.backward()

        x_adv = x_adv + alpha * x_adv.grad.sign()
        delta = torch.clamp(x_adv - x0, min=-eps, max=eps)
        x_adv = (x0 + delta).detach()

    return x_adv.detach()


# =========================
# Experiment runners (reuse split; NEW signature)
# =========================
def run_fgsm_nn_to_rf(
    *,
    cfg: AdversarialConfig,
    split: Dict[str, Any],
    scaler,
    nn_model: nn.Module,
    rf,
    clean_thr_nn: float,
    clean_thr_rf: float,
    results_dir: Path,
    artifacts_dir: Path,
) -> pd.DataFrame:
    results_dir = Path(results_dir)
    artifacts_dir = Path(artifacts_dir)
    results_dir.mkdir(parents=True, exist_ok=True)
    artifacts_dir.mkdir(parents=True, exist_ok=True)

    device = resolve_device(cfg.device)
    nn_model = nn_model.to(device)
    nn_model.eval()

    feature_cols = split["feature_cols"]
    clip_to_train_range = split["clip_to_train_range"]

    X_mal_scaled = split["X_mal_scaled"]
    y_mal_np = split["y_mal_np"]

    X_mal_t = torch.tensor(X_mal_scaled, dtype=torch.float32, device=device)
    y_mal_t = torch.ones(X_mal_t.shape[0], dtype=torch.float32, device=device)  # targeted malware evasion

    rows: List[Dict[str, Any]] = []

    for eps in cfg.eps_list:
        eps_f = float(eps)

        # generate adversarial (scaled)
        X_adv_scaled_t = fgsm_attack(nn_model, X_mal_t, y_mal_t, eps=eps_f)
        X_adv_scaled = X_adv_scaled_t.detach().cpu().numpy()
        np.save(artifacts_dir / f"X_adv_scaled_fgsm_eps{eps_f}.npy", X_adv_scaled)

        # NN eval on malware-only with FIXED clean threshold
        with torch.no_grad():
            adv_logits = nn_model(X_adv_scaled_t).squeeze(1)
            nn_probs_adv = torch.sigmoid(adv_logits).detach().cpu().numpy()
        nn_probs_adv = probs_guard(nn_probs_adv)
        pred_nn_fixed = (nn_probs_adv >= float(clean_thr_nn)).astype(int)
        fn_rate_nn_fixed = float((pred_nn_fixed == 0).mean())
        np.save(artifacts_dir / f"pred_nn_fgsm_eps{eps_f}_fixed.npy", pred_nn_fixed)

        # Transfer to RF: inverse scale -> clip -> finite DataFrame
        X_adv_raw = scaler.inverse_transform(X_adv_scaled)
        X_adv_raw = clip_to_train_range(X_adv_raw)
        X_adv_raw_df = pd.DataFrame(X_adv_raw, columns=feature_cols)
        X_adv_raw_df = _finite_df_from(X_adv_raw_df, fill_value=0.0)

        rf_probs_adv = rf.predict_proba(X_adv_raw_df)[:, 1]
        rf_probs_adv = probs_guard(rf_probs_adv)
        pred_rf_fixed = (rf_probs_adv >= float(clean_thr_rf)).astype(int)
        fn_rate_rf_fixed = float((pred_rf_fixed == 0).mean())
        np.save(artifacts_dir / f"pred_rf_transfer_fgsm_eps{eps_f}_fixed.npy", pred_rf_fixed)

        meta = {
            "attack": "FGSM",
            "eps": eps_f,
            "n_mal": int(len(y_mal_np)),
            "nn_clean_thr": float(clean_thr_nn),
            "rf_clean_thr": float(clean_thr_rf),
            "fn_rate_nn_fixed": fn_rate_nn_fixed,
            "fn_rate_rf_fixed_transfer": fn_rate_rf_fixed,
        }
        with open(results_dir / f"meta_fgsm_eps{eps_f}.json", "w", encoding="utf-8") as f:
            json.dump(meta, f, indent=2)

        rows.append(meta)

    df_out = pd.DataFrame(rows)
    df_out.to_csv(results_dir / "summary_fgsm.csv", index=False)
    print("[INFO] Saved FGSM summary:", results_dir / "summary_fgsm.csv")
    return df_out


def run_pgd_nn_to_rf(
    *,
    cfg: AdversarialConfig,
    split: Dict[str, Any],
    scaler,
    nn_model: nn.Module,
    rf,
    clean_thr_nn: float,
    clean_thr_rf: float,
    results_dir: Path,
    artifacts_dir: Path,
) -> pd.DataFrame:
    results_dir = Path(results_dir)
    artifacts_dir = Path(artifacts_dir)
    results_dir.mkdir(parents=True, exist_ok=True)
    artifacts_dir.mkdir(parents=True, exist_ok=True)

    device = resolve_device(cfg.device)
    nn_model = nn_model.to(device)
    nn_model.eval()

    feature_cols = split["feature_cols"]
    clip_to_train_range = split["clip_to_train_range"]

    X_mal_scaled = split["X_mal_scaled"]
    y_mal_np = split["y_mal_np"]

    X_mal_t = torch.tensor(X_mal_scaled, dtype=torch.float32, device=device)
    y_mal_t = torch.ones(X_mal_t.shape[0], dtype=torch.float32, device=device)  # targeted malware evasion

    rows: List[Dict[str, Any]] = []

    for eps in cfg.eps_list:
        eps_f = float(eps)

        if eps_f not in cfg.pgd_alpha or eps_f not in cfg.pgd_steps:
            raise KeyError(
                f"Missing PGD params for eps={eps_f}. "
                f"Have alpha keys={list(cfg.pgd_alpha.keys())}, steps keys={list(cfg.pgd_steps.keys())}"
            )

        alpha = float(cfg.pgd_alpha[eps_f])
        steps = int(cfg.pgd_steps[eps_f])

        X_adv_scaled_t = pgd_attack(
            nn_model,
            X_mal_t,
            y_mal_t,
            eps=eps_f,
            alpha=alpha,
            steps=steps,
        )
        X_adv_scaled = X_adv_scaled_t.detach().cpu().numpy()
        np.save(
            artifacts_dir / f"X_adv_scaled_pgd_eps{eps_f}_a{alpha}_s{steps}.npy",
            X_adv_scaled,
        )

        # NN eval
        with torch.no_grad():
            adv_logits = nn_model(X_adv_scaled_t).squeeze(1)
            nn_probs_adv = torch.sigmoid(adv_logits).detach().cpu().numpy()
        nn_probs_adv = probs_guard(nn_probs_adv)
        pred_nn_fixed = (nn_probs_adv >= float(clean_thr_nn)).astype(int)
        fn_rate_nn_fixed = float((pred_nn_fixed == 0).mean())
        np.save(artifacts_dir / f"pred_nn_pgd_eps{eps_f}_fixed.npy", pred_nn_fixed)

        # Transfer to RF
        X_adv_raw = scaler.inverse_transform(X_adv_scaled)
        X_adv_raw = clip_to_train_range(X_adv_raw)
        X_adv_raw_df = pd.DataFrame(X_adv_raw, columns=feature_cols)
        X_adv_raw_df = _finite_df_from(X_adv_raw_df, fill_value=0.0)

        rf_probs_adv = rf.predict_proba(X_adv_raw_df)[:, 1]
        rf_probs_adv = probs_guard(rf_probs_adv)
        pred_rf_fixed = (rf_probs_adv >= float(clean_thr_rf)).astype(int)
        fn_rate_rf_fixed = float((pred_rf_fixed == 0).mean())
        np.save(artifacts_dir / f"pred_rf_transfer_pgd_eps{eps_f}_fixed.npy", pred_rf_fixed)

        meta = {
            "attack": "PGD",
            "eps": eps_f,
            "alpha": alpha,
            "steps": steps,
            "n_mal": int(len(y_mal_np)),
            "nn_clean_thr": float(clean_thr_nn),
            "rf_clean_thr": float(clean_thr_rf),
            "fn_rate_nn_fixed": fn_rate_nn_fixed,
            "fn_rate_rf_fixed_transfer": fn_rate_rf_fixed,
        }
        with open(results_dir / f"meta_pgd_eps{eps_f}.json", "w", encoding="utf-8") as f:
            json.dump(meta, f, indent=2)

        rows.append(meta)

    df_out = pd.DataFrame(rows)
    df_out.to_csv(results_dir / "summary_pgd.csv", index=False)
    print("[INFO] Saved PGD summary:", results_dir / "summary_pgd.csv")
    return df_out


# Backward-compatible wrappers (so Notebook 03 can keep calling with data_csv if desired)
def run_fgsm_nn_to_rf_from_csv(
    *,
    cfg: AdversarialConfig,
    data_csv: Path,
    scaler,
    nn_model: nn.Module,
    rf,
    clean_thr_nn: float,
    clean_thr_rf: float,
    results_dir: Path,
    artifacts_dir: Path,
) -> pd.DataFrame:
    split = make_split_and_artifacts(
        data_csv=data_csv,
        scaler=scaler,
        artifacts_dir=artifacts_dir,
        random_state=cfg.random_state,
        test_size=0.2,
        nonfinite_fill=0.0,
    )
    return run_fgsm_nn_to_rf(
        cfg=cfg,
        split=split,
        scaler=scaler,
        nn_model=nn_model,
        rf=rf,
        clean_thr_nn=clean_thr_nn,
        clean_thr_rf=clean_thr_rf,
        results_dir=results_dir,
        artifacts_dir=artifacts_dir,
    )


def run_pgd_nn_to_rf_from_csv(
    *,
    cfg: AdversarialConfig,
    data_csv: Path,
    scaler,
    nn_model: nn.Module,
    rf,
    clean_thr_nn: float,
    clean_thr_rf: float,
    results_dir: Path,
    artifacts_dir: Path,
) -> pd.DataFrame:
    split = make_split_and_artifacts(
        data_csv=data_csv,
        scaler=scaler,
        artifacts_dir=artifacts_dir,
        random_state=cfg.random_state,
        test_size=0.2,
        nonfinite_fill=0.0,
    )
    return run_pgd_nn_to_rf(
        cfg=cfg,
        split=split,
        scaler=scaler,
        nn_model=nn_model,
        rf=rf,
        clean_thr_nn=clean_thr_nn,
        clean_thr_rf=clean_thr_rf,
        results_dir=results_dir,
        artifacts_dir=artifacts_dir,
    )


# =========================
# Merge + plot
# =========================
def merge_and_plot_targeted_evasion_summary(
    *,
    fgsm_df: pd.DataFrame,
    pgd_df: pd.DataFrame,
    results_dir: Path,
) -> Tuple[pd.DataFrame, Path]:
    results_dir = Path(results_dir)
    results_dir.mkdir(parents=True, exist_ok=True)

    fgsm = fgsm_df.copy()
    pgd = pgd_df.copy()
    fgsm["attack"] = "FGSM"
    pgd["attack"] = "PGD"
    all_res = pd.concat([fgsm, pgd], ignore_index=True)

    out_csv = results_dir / "summary_targeted_evasion.csv"
    all_res.to_csv(out_csv, index=False)
    print("[INFO] Saved:", out_csv)

    # Plot FN rates vs eps
    fig, ax = plt.subplots(figsize=(7, 4))
    for attack_name, grp in all_res.groupby("attack"):
        grp = grp.sort_values("eps")
        ax.plot(grp["eps"], grp["fn_rate_nn_fixed"], marker="o", label=f"NN (fixed) - {attack_name}")
        ax.plot(
            grp["eps"],
            grp["fn_rate_rf_fixed_transfer"],
            marker="x",
            linestyle="--",
            label=f"RF transfer (fixed) - {attack_name}",
        )

    ax.set_title("Targeted Evasion Success (FN rate on malware) vs Epsilon")
    ax.set_xlabel("Epsilon (scaled feature space)")
    ax.set_ylabel("Evasion success rate (malware -> benign)")
    ax.grid(True, alpha=0.3)
    ax.legend()
    plt.tight_layout()

    out_png = results_dir / "targeted_evasion_summary.png"
    fig.savefig(out_png, dpi=300, bbox_inches="tight")
    plt.show()

    return all_res, out_png


__all__ = [
    "AdversarialConfig",
    "resolve_device",
    "load_binary_artifacts",
    "make_split_and_artifacts",
    "compute_clean_thresholds",
    "compute_clean_thresholds_from_split",
    "fgsm_attack",
    "pgd_attack",
    "run_fgsm_nn_to_rf",
    "run_pgd_nn_to_rf",
    "run_fgsm_nn_to_rf_from_csv",
    "run_pgd_nn_to_rf_from_csv",
    "merge_and_plot_targeted_evasion_summary",
    "probs_guard",
    "youden_threshold",
]